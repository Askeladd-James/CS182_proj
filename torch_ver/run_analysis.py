"""
ç‹¬ç«‹çš„æ¨¡å‹åˆ†æè„šæœ¬ - å¯åœ¨å·²æœ‰è®­ç»ƒç»“æœåŸºç¡€ä¸Šç”Ÿæˆå›¾è¡¨
"""
import argparse
from pathlib import Path
from data_process import data_path
from train_comparison import rebuild_summary_standalone
import json

def check_and_rebuild_summary():
    """æ£€æŸ¥å¹¶é‡å»ºæ±‡æ€»æ–‡ä»¶"""
    summary_path = Path(data_path).parent / "results" / "all_models_summary_with_baseline_new.json"
    
    print("ğŸ“„ æ£€æŸ¥æ±‡æ€»æ–‡ä»¶...")
    
    if not summary_path.exists():
        print("âŒ æ±‡æ€»æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨é‡å»º...")
        summary_data = rebuild_summary_standalone()
        if not summary_data:
            print("âŒ é‡å»ºæ±‡æ€»æ–‡ä»¶å¤±è´¥")
            return None
    else:
        print(f"âœ… å‘ç°æ±‡æ€»æ–‡ä»¶: {summary_path.name}")
        
        # è¯»å–å¹¶éªŒè¯æ±‡æ€»æ–‡ä»¶
        try:
            with open(summary_path, "r", encoding="utf-8") as f:
                summary_data = json.load(f)
            
            if not summary_data:
                print("âš ï¸ æ±‡æ€»æ–‡ä»¶ä¸ºç©ºï¼Œæ­£åœ¨é‡å»º...")
                summary_data = rebuild_summary_standalone()
            else:
                print(f"ğŸ“Š æ±‡æ€»æ–‡ä»¶åŒ…å« {len(summary_data)} ä¸ªæ¨¡å‹")
                
        except Exception as e:
            print(f"âŒ è¯»å–æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}")
            print("ğŸ”„ æ­£åœ¨é‡å»ºæ±‡æ€»æ–‡ä»¶...")
            summary_data = rebuild_summary_standalone()
    
    return summary_data

def validate_summary_data(summary_data):
    """éªŒè¯æ±‡æ€»æ•°æ®çš„å®Œæ•´æ€§"""
    if not summary_data:
        return False, "æ±‡æ€»æ•°æ®ä¸ºç©º"
    
    # æ£€æŸ¥å¿…è¦çš„æ¨¡å‹ç±»å‹
    expected_models = [
        "CFModel_Baseline",
        "UserTime", 
        "IndependentTime",
        "UMTime",
        "TwoStage_MMoE"
    ]
    
    missing_models = []
    for model_type in expected_models:
        if model_type not in summary_data:
            missing_models.append(model_type)
    
    if missing_models:
        return False, f"ç¼ºå°‘æ¨¡å‹: {missing_models}"
    
    # æ£€æŸ¥æ¯ä¸ªæ¨¡å‹çš„å¿…è¦æ•°æ®
    for model_type, data in summary_data.items():
        if not isinstance(data, dict):
            return False, f"æ¨¡å‹ {model_type} æ•°æ®æ ¼å¼é”™è¯¯"
        
        if "test_metrics" not in data:
            return False, f"æ¨¡å‹ {model_type} ç¼ºå°‘æµ‹è¯•æŒ‡æ ‡"
        
        if "training_history" not in data:
            return False, f"æ¨¡å‹ {model_type} ç¼ºå°‘è®­ç»ƒå†å²"
    
    return True, "æ•°æ®éªŒè¯é€šè¿‡"

def main():
    """ç‹¬ç«‹åˆ†æä¸»å‡½æ•°"""
    print("ğŸ” ç‹¬ç«‹æ¨¡å‹åˆ†æå·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥è®­ç»ƒç»“æœç›®å½•æ˜¯å¦å­˜åœ¨
    results_dir = Path(data_path) / "results"
    if not results_dir.exists():
        print("âŒ ç»“æœç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ¨¡å‹è®­ç»ƒ")
        print("ğŸ’¡ è¿è¡Œ: python train_comparison.py")
        return None
    
    # ğŸ”§ æ–°å¢ï¼šæ£€æŸ¥å¹¶å¤„ç†æ±‡æ€»æ–‡ä»¶
    summary_data = check_and_rebuild_summary()
    if not summary_data:
        print("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„æ±‡æ€»æ•°æ®")
        return None
    
    # ğŸ”§ æ–°å¢ï¼šéªŒè¯æ±‡æ€»æ•°æ®
    is_valid, message = validate_summary_data(summary_data)
    if not is_valid:
        print(f"âŒ æ±‡æ€»æ•°æ®éªŒè¯å¤±è´¥: {message}")
        print("ğŸ”„ å°è¯•é‡å»ºæ±‡æ€»æ–‡ä»¶...")
        summary_data = rebuild_summary_standalone()
        
        if not summary_data:
            print("âŒ é‡å»ºåä»æ— æ³•è·å–æœ‰æ•ˆæ•°æ®")
            return None
        
        # å†æ¬¡éªŒè¯
        is_valid, message = validate_summary_data(summary_data)
        if not is_valid:
            print(f"âŒ é‡å»ºåéªŒè¯ä»å¤±è´¥: {message}")
            return None
    
    print(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {message}")
    
    # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºå¯ç”¨æ¨¡å‹ä¿¡æ¯
    print("\nğŸ“‹ å¯ç”¨æ¨¡å‹:")
    for model_type, data in summary_data.items():
        model_name = data.get("model_name", model_type)
        test_rmse = data.get("test_metrics", {}).get("RMSE", "N/A")
        print(f"  - {model_name}: RMSE = {test_rmse}")
    
    print("\nğŸš€ å¼€å§‹ç”Ÿæˆåˆ†æå›¾è¡¨...")
    
    try:
        # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æ±‡æ€»æ–‡ä»¶è·¯å¾„è¿è¡Œåˆ†æ
        import model_comparison
        
        # ä¼ é€’æ±‡æ€»æ–‡ä»¶è·¯å¾„ç»™åˆ†æå™¨
        summary_path = Path(data_path) / "results" / "all_models_summary_with_baseline_new.json"
        analyzer = model_comparison.ModelComparison(results_path=str(summary_path))
        
        # è¿è¡Œå®Œæ•´åˆ†æ
        analyzer.run_complete_analysis()
        
        print("âœ… åˆ†æå®Œæˆï¼")
        print("\nğŸ“ˆ ç”Ÿæˆçš„å›¾è¡¨:")
        
        # åˆ—å‡ºç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶
        plots_dir = analyzer.output_dir
        if plots_dir.exists():
            plot_files = list(plots_dir.glob("*.png"))
            plot_files.sort()
            
            for i, plot_file in enumerate(plot_files, 1):
                print(f"  {i:2d}. {plot_file.name}")
            
            print(f"\nğŸ“ å›¾è¡¨ä¿å­˜ä½ç½®: {plots_dir}")
        
        return analyzer
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None

def rebuild_summary_only():
    """ä»…é‡å»ºæ±‡æ€»æ–‡ä»¶çš„ç‹¬ç«‹å‡½æ•°"""
    print("ğŸ”„ é‡å»ºæ±‡æ€»æ–‡ä»¶æ¨¡å¼")
    print("=" * 60)
    
    try:
        summary_data = rebuild_summary_standalone()
        
        if summary_data:
            print(f"âœ… æ±‡æ€»æ–‡ä»¶é‡å»ºæˆåŠŸ! åŒ…å« {len(summary_data)} ä¸ªæ¨¡å‹")
            
            # éªŒè¯é‡å»ºçš„æ•°æ®
            is_valid, message = validate_summary_data(summary_data)
            if is_valid:
                print(f"âœ… æ•°æ®éªŒè¯é€šè¿‡: {message}")
            else:
                print(f"âš ï¸ æ•°æ®éªŒè¯è­¦å‘Š: {message}")
            
            return summary_data
        else:
            print("âŒ æ±‡æ€»æ–‡ä»¶é‡å»ºå¤±è´¥")
            return None
            
    except Exception as e:
        print(f"âŒ é‡å»ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None

if __name__ == "__main__":
    # ğŸ”§ æ–°å¢ï¼šæ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="æ¨¡å‹åˆ†æå·¥å…·")
    parser.add_argument(
        "--mode", 
        choices=["analyze", "rebuild"], 
        default="analyze",
        help="è¿è¡Œæ¨¡å¼: analyze=ç”Ÿæˆåˆ†æå›¾è¡¨, rebuild=é‡å»ºæ±‡æ€»æ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    if args.mode == "rebuild":
        # ä»…é‡å»ºæ±‡æ€»æ–‡ä»¶
        summary_data = rebuild_summary_only()
        
        if summary_data:
            print("\n" + "="*60)
            print("ğŸ‰ æ±‡æ€»æ–‡ä»¶é‡å»ºå®Œæˆï¼")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥è¿è¡Œ: python run_analysis.py --mode analyze")
            print("="*60)
        else:
            print("\n" + "="*60)
            print("âŒ æ±‡æ€»æ–‡ä»¶é‡å»ºå¤±è´¥")
            print("="*60)
    
    else:
        # è¿è¡Œå®Œæ•´åˆ†æ
        analyzer = main()
        
        if analyzer:
            print("\n" + "="*60)
            print("ğŸ‰ ç‹¬ç«‹åˆ†æå®Œæˆï¼")
            print("ğŸ“Š æ‰€æœ‰å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ")
            print("="*60)
        else:
            print("\n" + "="*60)
            print("âŒ åˆ†æå¤±è´¥")
            print("ğŸ’¡ å»ºè®®è¿è¡Œ: python run_analysis.py --mode rebuild")
            print("="*60)