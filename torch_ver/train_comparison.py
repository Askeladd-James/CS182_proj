import torch
import torch.nn as nn
import torch.optim as optim
from data_process import (
    load_data,
    create_time_aware_split,
    save_split_data,
    check_split_data_exists,
    load_existing_split_data,
    MovieLensDataset,
    data_path,
)
from model import (
    IndependentTimeModel,
    UserTimeModel,
    UMTimeModel,
    TwoStageMMoEModel,
    CFModel,
)
from torch.utils.data import DataLoader
import logging
import math
import pandas as pd
import json
import time
import numpy as np
from pathlib import Path

def prepare_config_for_json(config):
    """å‡†å¤‡é…ç½®ä»¥ä¾¿JSONåºåˆ—åŒ–ï¼ˆå°†deviceå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰"""
    json_config = config.copy()
    if 'DEVICE' in json_config:
        json_config['DEVICE'] = str(json_config['DEVICE'])
    return json_config

def train_model_with_metrics(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    scheduler,
    device,
    num_epochs=30,
    patience=10,
):
    """è®­ç»ƒæ¨¡å‹ï¼Œè®°å½•è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡"""
    best_val_loss = float("inf")
    patience_counter = 0
    best_model_state = None

    # è®°å½•è®­ç»ƒæŒ‡æ ‡
    training_history = {
        "train_losses": [],
        "val_losses": [],
        "train_rmse": [],
        "val_rmse": [],
        "learning_rates": [],
        "epoch_times": [],
        "best_epoch": 0,
        "total_epochs": 0,
    }

    logging.info(f"å¼€å§‹è®­ç»ƒæ¨¡å‹: {model.name}")
    start_time = time.time()

    for epoch in range(num_epochs):
        epoch_start = time.time()

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        num_batches = 0

        for user, movie, rating, daytime, weekend, year in train_loader:
            user = user.to(device)
            movie = movie.to(device)
            rating = rating.to(device)
            daytime = daytime.to(device)
            weekend = weekend.to(device)
            year = year.to(device)

            optimizer.zero_grad()
            prediction = model(user, movie, daytime, weekend, year)

            # è®¡ç®—æŸå¤±ï¼ˆMSE + L2æ­£åˆ™åŒ–ï¼‰
            mse_loss = criterion(prediction, rating)

            # å¦‚æœæ¨¡å‹æœ‰æ­£åˆ™åŒ–æ–¹æ³•ï¼Œæ·»åŠ æ­£åˆ™åŒ–æŸå¤±
            if hasattr(model, "get_regularization_loss"):
                reg_loss = model.get_regularization_loss()
                total_loss = mse_loss + reg_loss
            else:
                total_loss = mse_loss

            total_loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()
            train_loss += mse_loss.item()  # åªè®°å½•MSEç”¨äºæ¯”è¾ƒ
            num_batches += 1

        avg_train_loss = train_loss / num_batches
        train_rmse = math.sqrt(avg_train_loss)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        num_val_batches = 0

        with torch.no_grad():
            for user, movie, rating, daytime, weekend, year in val_loader:
                user = user.to(device)
                movie = movie.to(device)
                rating = rating.to(device)
                daytime = daytime.to(device)
                weekend = weekend.to(device)
                year = year.to(device)

                prediction = model(user, movie, daytime, weekend, year)
                loss = criterion(prediction, rating)
                val_loss += loss.item()
                num_val_batches += 1

        avg_val_loss = val_loss / num_val_batches
        val_rmse = math.sqrt(avg_val_loss)

        # è®°å½•å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]["lr"]

        # å­¦ä¹ ç‡è°ƒåº¦
        if scheduler:
            scheduler.step(avg_val_loss)

        # è®°å½•æŒ‡æ ‡
        training_history["train_losses"].append(avg_train_loss)
        training_history["val_losses"].append(avg_val_loss)
        training_history["train_rmse"].append(train_rmse)
        training_history["val_rmse"].append(val_rmse)
        training_history["learning_rates"].append(current_lr)

        epoch_time = time.time() - epoch_start
        training_history["epoch_times"].append(epoch_time)

        # æ‰“å°è®­ç»ƒä¿¡æ¯
        logging.info(f"Epoch {epoch+1}/{num_epochs} ({epoch_time:.2f}s)")
        logging.info(f"Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}")
        logging.info(f"Val Loss: {avg_val_loss:.4f}, Val RMSE: {val_rmse:.4f}")
        logging.info(f"Learning rate: {current_lr:.6f}")

        # æ—©åœæ£€æŸ¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            training_history["best_epoch"] = epoch
            logging.info(f"New best validation loss: {avg_val_loss:.4f}")
        else:
            patience_counter += 1

        if patience_counter >= patience:
            logging.info(f"Early stopping at epoch {epoch+1}")
            if best_model_state is not None:
                model.load_state_dict(best_model_state)
            break

    training_history["total_epochs"] = epoch + 1
    total_time = time.time() - start_time
    training_history["total_training_time"] = total_time

    # æœ€ç»ˆç»Ÿè®¡
    best_rmse = math.sqrt(best_val_loss)
    logging.info(f"è®­ç»ƒå®Œæˆï¼æ€»æ—¶é—´: {total_time:.2f}s")
    logging.info(f"Best validation loss: {best_val_loss:.4f}")
    logging.info(f"Best validation RMSE: {best_rmse:.4f}")

    return best_model_state, training_history


def evaluate_model_detailed(model, test_data, device):
    """è¯¦ç»†è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    model.eval()
    predictions = []
    actuals = []

    start_time = time.time()

    with torch.no_grad():
        for _, row in test_data.iterrows():
            user_id = torch.LongTensor([row["user_emb_id"]]).to(device)
            movie_id = torch.LongTensor([row["movie_emb_id"]]).to(device)
            daytime = torch.LongTensor([row["daytime"]]).to(device)
            weekend = torch.LongTensor([row["is_weekend"]]).to(device)
            year = torch.LongTensor([row["year"]]).to(device)

            pred = model(user_id, movie_id, daytime, weekend, year)
            predictions.append(pred.cpu().item())
            actuals.append(row["rating"])

    inference_time = time.time() - start_time

    # è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡
    predictions = np.array(predictions)
    actuals = np.array(actuals)

    # åŸºæœ¬æŒ‡æ ‡
    mse = np.mean((predictions - actuals) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(predictions - actuals))

    # å…¶ä»–æŒ‡æ ‡
    mape = (
        np.mean(np.abs((actuals - predictions) / actuals)) * 100
    )  # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®

    # è¯„åˆ†åˆ†å¸ƒç»Ÿè®¡
    pred_mean = np.mean(predictions)
    pred_std = np.std(predictions)
    actual_mean = np.mean(actuals)
    actual_std = np.std(actuals)

    # ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(predictions, actuals)[0, 1]

    # æŒ‰è¯„åˆ†åŒºé—´çš„å‡†ç¡®åº¦
    rating_accuracy = {}
    for rating in [1, 2, 3, 4, 5]:
        mask = actuals == rating
        if np.sum(mask) > 0:
            rating_predictions = predictions[mask]
            rating_mae = np.mean(np.abs(rating_predictions - rating))
            rating_accuracy[f"rating_{rating}_mae"] = rating_mae

    return {
        "MSE": mse,
        "RMSE": rmse,
        "MAE": mae,
        "MAPE": mape,
        "Correlation": correlation,
        "Inference_Time": inference_time,
        "Predictions_Mean": pred_mean,
        "Predictions_Std": pred_std,
        "Actuals_Mean": actual_mean,
        "Actuals_Std": actual_std,
        "predictions": predictions.tolist(),
        "actuals": actuals.tolist(),
        **rating_accuracy,
    }


def train_and_evaluate_model(
    model_class,
    model_name,
    max_userid,
    max_movieid,
    train_loader,
    val_loader,
    test_data,
    device,
    config,
):
    """è®­ç»ƒå’Œè¯„ä¼°ä¼ ç»Ÿæ¨¡å‹çš„é€šç”¨å‡½æ•° - ä¿®å¤JSONåºåˆ—åŒ–"""
    logging.info(f"\n{'='*60}")
    logging.info(f"å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹: {model_name}")
    logging.info(f"{'='*60}")

    # åˆ›å»ºæ¨¡å‹
    model = model_class(
        max_userid + 1,
        max_movieid + 1,
        config["K_FACTORS"],
        config["TIME_FACTORS"],
        config["REG_STRENGTH"],
    ).to(device)

    # ç»Ÿè®¡æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    logging.info(
        f"{model_name}å‚æ•°: æ€»æ•°={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}"
    )

    # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    criterion = nn.MSELoss()
    optimizer = optim.Adam(
        model.parameters(), lr=config["LEARNING_RATE"], weight_decay=1e-6
    )

    # ä½¿ç”¨ReduceLROnPlateauè°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.6, patience=5, min_lr=1e-6
    )

    # è®­ç»ƒæ¨¡å‹
    best_model_state, training_history = train_model_with_metrics(
        model,
        train_loader,
        val_loader,
        criterion,
        optimizer,
        scheduler,
        device,
        config["NUM_EPOCHS"],
        patience=10,
    )

    # è¯„ä¼°æ¨¡å‹
    logging.info(f"å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_name}")
    test_metrics = evaluate_model_detailed(model, test_data, device)

    # æ•´ç†ç»“æœ - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜
    results = {
        "model_name": model_name,
        "model_type": model.name,
        "training_history": training_history,
        "test_metrics": test_metrics,
        "model_params": {
            "total_params": total_params,
            "trainable_params": trainable_params,
            "k_factors": config["K_FACTORS"],
            "time_factors": config["TIME_FACTORS"],
            "reg_strength": config["REG_STRENGTH"],
        },
        "training_config": prepare_config_for_json(config),  # ä¿®å¤ï¼šè½¬æ¢deviceä¸ºå­—ç¬¦ä¸²
    }

    # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
    checkpoint = {
        "max_userid": max_userid,
        "max_movieid": max_movieid,
        "k_factors": config["K_FACTORS"],
        "time_factors": config["TIME_FACTORS"],
        "reg_strength": config["REG_STRENGTH"],
        "best_model_state": model.state_dict(),
        "model_type": model.name,
        "training_history": training_history,
        "test_metrics": test_metrics,
        "has_scheduler": True,
    }

    model_path = data_path + f"model/model_checkpoint_{model.name}_with_scheduler.pt"
    torch.save(checkpoint, model_path, _use_new_zipfile_serialization=False)
    logging.info(f"æ¨¡å‹ä¿å­˜è‡³: {model_path}")

    # ä¿å­˜ç»“æœJSON - ç°åœ¨åº”è¯¥ä¸ä¼šå‡ºç°åºåˆ—åŒ–é”™è¯¯
    results_path = data_path + f"results/results_{model.name}_with_scheduler.json"
    Path(results_path).parent.mkdir(exist_ok=True)
    with open(results_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logging.info(f"æ¨¡å‹ {model_name} è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!")
    logging.info(f"æµ‹è¯• RMSE: {test_metrics['RMSE']:.4f}")
    logging.info(f"æµ‹è¯• MAE: {test_metrics['MAE']:.4f}")

    return results


def train_and_evaluate_mmoe_model(
    model_name, max_userid, max_movieid, train_data, val_data, test_data, device, config
):
    """MMOEæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° - ä¿®å¤JSONåºåˆ—åŒ–"""
    logging.info(f"\n{'='*60}")
    logging.info(f"å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°MMOEæ¨¡å‹: {model_name}")
    logging.info(f"{'='*60}")

    # åˆ›å»ºMMOEæ¨¡å‹
    model = TwoStageMMoEModel(
        max_userid + 1,
        max_movieid + 1,
        config["K_FACTORS"],
        config["TIME_FACTORS"],
        config["REG_STRENGTH"],
        config["NUM_EXPERTS"],
    ).to(device)

    # ç»Ÿè®¡æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    logging.info(f"MMOEæ¨¡å‹å‚æ•°: æ€»æ•°={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}")

    # è®­ç»ƒå†å²è®°å½•ï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰
    all_training_history = {
        "train_losses": [],
        "val_losses": [],
        "train_rmse": [],
        "val_rmse": [],
        "learning_rates": [],
        "epoch_times": [],
        "best_epoch": 0,
        "total_epochs": 0,
    }

    criterion = nn.MSELoss()
    start_time = time.time()

    # ä½¿ç”¨MMOEè®­ç»ƒå‡½æ•°
    from MMOE_train import train_mmoe

    try:
        # ä¿®å¤ï¼šæ­£ç¡®ä¼ é€’MMOEä¸“ç”¨å‚æ•°
        model, mmoe_history = train_mmoe(
            model,
            train_data,
            val_data,
            device,
            batch_size=config["BATCH_SIZE"],
            num_epochs_per_stage=config.get('NUM_EPOCHS_PER_STAGE', [8, 12, 8]),
            learning_rates=config.get('LEARNING_RATES', [0.001, 0.001, 0.0005])
        )

        # æ•´åˆè®­ç»ƒå†å²ï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰
        total_training_time = time.time() - start_time

        # å¦‚æœmmoe_historyæ˜¯å­—å…¸æ ¼å¼ï¼ˆåŒ…å«å„é˜¶æ®µå†å²ï¼‰
        if isinstance(mmoe_history, dict) and any('stage' in key.lower() for key in mmoe_history.keys()):
            for stage_name, stage_history in mmoe_history.items():
                if isinstance(stage_history, dict):
                    # åˆå¹¶å„é˜¶æ®µçš„è®­ç»ƒæŸå¤±
                    if "train_losses" in stage_history:
                        all_training_history["train_losses"].extend(stage_history["train_losses"])
                    if "val_losses" in stage_history:
                        all_training_history["val_losses"].extend(stage_history["val_losses"])

                    # è®¡ç®—RMSE
                    if "train_losses" in stage_history:
                        stage_train_rmse = [math.sqrt(loss) for loss in stage_history["train_losses"]]
                        all_training_history["train_rmse"].extend(stage_train_rmse)
                    if "val_losses" in stage_history:
                        stage_val_rmse = [math.sqrt(loss) for loss in stage_history["val_losses"]]
                        all_training_history["val_rmse"].extend(stage_val_rmse)

                    # åˆå¹¶å­¦ä¹ ç‡å†å²
                    if "learning_rates" in stage_history:
                        all_training_history["learning_rates"].extend(stage_history["learning_rates"])
                    else:
                        # å¦‚æœæ²¡æœ‰å­¦ä¹ ç‡è®°å½•ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        stage_epochs = stage_history.get("total_epochs", 1)
                        all_training_history["learning_rates"].extend([0.001] * stage_epochs)

                    # åˆå¹¶è®­ç»ƒæ—¶é—´
                    if "epoch_times" in stage_history:
                        all_training_history["epoch_times"].extend(stage_history["epoch_times"])
                    else:
                        stage_epochs = stage_history.get("total_epochs", 1)
                        all_training_history["epoch_times"].extend([1.0] * stage_epochs)
        
        # å¦‚æœmmoe_historyæ˜¯ç›´æ¥çš„å†å²è®°å½•æ ¼å¼
        elif isinstance(mmoe_history, dict):
            for key in ["train_losses", "val_losses", "learning_rates", "epoch_times"]:
                if key in mmoe_history:
                    all_training_history[key] = mmoe_history[key]
            
            # è®¡ç®—RMSE
            if "train_losses" in mmoe_history:
                all_training_history["train_rmse"] = [math.sqrt(loss) for loss in mmoe_history["train_losses"]]
            if "val_losses" in mmoe_history:
                all_training_history["val_rmse"] = [math.sqrt(loss) for loss in mmoe_history["val_losses"]]

        # è®¾ç½®æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
        all_training_history["total_training_time"] = total_training_time
        
        if isinstance(mmoe_history, dict) and "total_epochs" in mmoe_history:
            all_training_history["total_epochs"] = mmoe_history["total_epochs"]
        elif isinstance(mmoe_history, dict) and any('stage' in key.lower() for key in mmoe_history.keys()):
            all_training_history["total_epochs"] = sum(
                stage_history.get("total_epochs", 0) 
                for stage_history in mmoe_history.values() 
                if isinstance(stage_history, dict)
            )
        else:
            all_training_history["total_epochs"] = len(all_training_history.get("train_losses", []))
        
        # è®¾ç½®æœ€ä½³è½®æ¬¡
        if all_training_history["val_losses"]:
            best_epoch_idx = np.argmin(all_training_history["val_losses"])
            all_training_history["best_epoch"] = best_epoch_idx
        else:
            all_training_history["best_epoch"] = len(all_training_history.get("train_losses", [])) - 1

    except Exception as e:
        logging.error(f"MMOEè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        
        # ä½¿ç”¨é»˜è®¤å†å²è®°å½•
        all_training_history["total_training_time"] = time.time() - start_time
        all_training_history["total_epochs"] = 0
        all_training_history["best_epoch"] = 0
        
        # å¦‚æœè®­ç»ƒå¤±è´¥ï¼Œé‡æ–°æŠ›å‡ºå¼‚å¸¸
        raise

    # è¯„ä¼°MMOEæ¨¡å‹ï¼ˆä¿æŒåŸæœ‰æµç¨‹ï¼‰
    model.set_training_stage(4)  # è§£å†»æ‰€æœ‰å‚æ•°ç”¨äºè¯„ä¼°
    logging.info(f"å¼€å§‹è¯„ä¼°MMOEæ¨¡å‹: {model_name}")
    test_metrics = evaluate_mmoe_model(model, test_data, device)

    # æ•´ç†ç»“æœï¼ˆä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜ï¼‰
    results = {
        "model_name": model_name,
        "model_type": model.name if hasattr(model, 'name') else 'TwoStageMMoE',
        "training_history": all_training_history,
        "test_metrics": test_metrics,
        "model_params": {
            "total_params": total_params,
            "trainable_params": trainable_params,
            "k_factors": config["K_FACTORS"],
            "time_factors": config["TIME_FACTORS"],
            "reg_strength": config["REG_STRENGTH"],
            "num_experts": config["NUM_EXPERTS"],
        },
        "training_config": prepare_config_for_json(config),  # ä¿®å¤ï¼šè½¬æ¢deviceä¸ºå­—ç¬¦ä¸²
    }

    # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰
    model_type_name = model.name if hasattr(model, 'name') else 'TwoStageMMoE'
    checkpoint = {
        "max_userid": max_userid,
        "max_movieid": max_movieid,
        "k_factors": config["K_FACTORS"],
        "time_factors": config["TIME_FACTORS"],
        "reg_strength": config["REG_STRENGTH"],
        "num_experts": config["NUM_EXPERTS"],
        "best_model_state": model.state_dict(),
        "model_type": model_type_name,
        "training_history": all_training_history,
        "test_metrics": test_metrics,
        "has_scheduler": True,
    }

    model_path = data_path + f"model/model_checkpoint_{model_type_name}_with_scheduler.pt"
    torch.save(checkpoint, model_path, _use_new_zipfile_serialization=False)
    logging.info(f"æ¨¡å‹ä¿å­˜è‡³: {model_path}")

    # ä¿å­˜ç»“æœJSONï¼ˆä¿®å¤åºåˆ—åŒ–é—®é¢˜ï¼‰
    results_path = data_path + f"results/results_{model_type_name}_with_scheduler.json"
    Path(results_path).parent.mkdir(exist_ok=True)
    with open(results_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logging.info(f"MMOEæ¨¡å‹ {model_name} è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!")
    logging.info(f"æµ‹è¯• RMSE: {test_metrics['RMSE']:.4f}")
    logging.info(f"æµ‹è¯• MAE: {test_metrics['MAE']:.4f}")
    
    # æ‰“å°è®­ç»ƒå†å²æ‘˜è¦
    if all_training_history["train_losses"]:
        final_train_loss = all_training_history["train_losses"][-1]
        logging.info(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.4f}")
    
    if all_training_history["val_losses"]:
        best_val_loss = min(all_training_history["val_losses"])
        logging.info(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
    
    logging.info(f"æ€»è®­ç»ƒè½®æ¬¡: {all_training_history['total_epochs']}")
    logging.info(f"è®­ç»ƒæ—¶é—´: {all_training_history['total_training_time']:.2f}ç§’")

    return results

def evaluate_mmoe_model(model, test_data, device):
    """ä¸“é—¨ä¸ºMMOEæ¨¡å‹çš„è¯„ä¼°å‡½æ•° - ä¿®å¤ç»´åº¦é”™è¯¯"""
    model.eval()
    predictions = []
    actuals = []

    start_time = time.time()

    # å‡†å¤‡ç”¨æˆ·å†å²ç»Ÿè®¡ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºè¯„ä¼°ï¼‰
    from MMOE_train import prepare_user_history_stats

    user_history_stats = prepare_user_history_stats(test_data)

    with torch.no_grad():
        for _, row in test_data.iterrows():
            user_id = torch.LongTensor([row["user_emb_id"]]).to(device)
            movie_id = torch.LongTensor([row["movie_emb_id"]]).to(device)
            daytime = torch.LongTensor([row["daytime"]]).to(device)
            weekend = torch.LongTensor([row["is_weekend"]]).to(device)
            year = torch.LongTensor([row["year"]]).to(device)

            # è·å–ç”¨æˆ·å†å²ç‰¹å¾
            user_emb_id = row["user_emb_id"]
            if user_emb_id in user_history_stats:
                history_features = (
                    torch.FloatTensor(user_history_stats[user_emb_id])
                    .unsqueeze(0)
                    .to(device)
                )
            else:
                history_features = (
                    torch.FloatTensor([3.0, 1.0, 1.0, 3.0, 0.0]).unsqueeze(0).to(device)
                )

            # ä½¿ç”¨é˜¶æ®µ4è¿›è¡Œå®Œæ•´è¯„ä¼°
            model.set_training_stage(4)
            final_pred = model(
                user_id, movie_id, daytime, weekend, year, user_history_features=history_features
            )

            # ç¡®ä¿é¢„æµ‹å€¼æ˜¯æ ‡é‡
            if final_pred.dim() > 0:
                final_pred = final_pred.item()
            else:
                final_pred = final_pred.item()

            predictions.append(final_pred)
            actuals.append(row["rating"])

    inference_time = time.time() - start_time

    # è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡ï¼ˆä¸åŸå‡½æ•°ç›¸åŒï¼‰
    predictions = np.array(predictions)
    actuals = np.array(actuals)

    # åŸºæœ¬æŒ‡æ ‡
    mse = np.mean((predictions - actuals) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(predictions - actuals))

    # å…¶ä»–æŒ‡æ ‡
    mape = (
        np.mean(np.abs((actuals - predictions) / actuals)) * 100
    )  # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®

    # è¯„åˆ†åˆ†å¸ƒç»Ÿè®¡
    pred_mean = np.mean(predictions)
    pred_std = np.std(predictions)
    actual_mean = np.mean(actuals)
    actual_std = np.std(actuals)

    # ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(predictions, actuals)[0, 1]

    # æŒ‰è¯„åˆ†åŒºé—´çš„å‡†ç¡®åº¦
    rating_accuracy = {}
    for rating in [1, 2, 3, 4, 5]:
        mask = actuals == rating
        if np.sum(mask) > 0:
            rating_predictions = predictions[mask]
            rating_mae = np.mean(np.abs(rating_predictions - rating))
            rating_accuracy[f"rating_{rating}_mae"] = rating_mae

    return {
        "MSE": mse,
        "RMSE": rmse,
        "MAE": mae,
        "MAPE": mape,
        "Correlation": correlation,
        "Inference_Time": inference_time,
        "Predictions_Mean": pred_mean,
        "Predictions_Std": pred_std,
        "Actuals_Mean": actual_mean,
        "Actuals_Std": actual_std,
        "predictions": predictions.tolist(),
        "actuals": actuals.tolist(),
        **rating_accuracy,
    }


def train_and_evaluate_baseline_model(
    model_name, max_userid, max_movieid, train_data, val_data, test_data, device, config
):
    """Baselineæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°å‡½æ•° - ä¿®æ­£ç‰ˆæœ¬"""
    logging.info(f"\n{'='*60}")
    logging.info(f"å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°Baselineæ¨¡å‹: {model_name}")
    logging.info(f"{'='*60}")

    # å¯¼å…¥baselineæ¨¡å‹ï¼ˆCFModelå·²ç»åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼‰
    from model import CFModel

    # åˆ›å»ºBaselineæ¨¡å‹
    model = CFModel(
        max_userid + 1,
        max_movieid + 1,
        100,  # baselineä½¿ç”¨100ä¸ªå› å­
        0.0001,  # baselineä½¿ç”¨è¾ƒä½æ­£åˆ™åŒ–
    ).to(device)

    # è®¾ç½®æ¨¡å‹çš„nameå±æ€§ï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
    if not hasattr(model, "name"):
        model.name = "CFModel_Baseline"

    # ç»Ÿè®¡æ¨¡å‹å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    logging.info(
        f"Baselineæ¨¡å‹å‚æ•°: æ€»æ•°={total_params:,}, å¯è®­ç»ƒ={trainable_params:,}"
    )

    # åˆ›å»ºbaselineä¸“ç”¨çš„æ•°æ®åŠ è½½å™¨ï¼ˆä¸éœ€è¦æ—¶é—´ç‰¹å¾ï¼‰
    baseline_train_dataset = BaselineDataset(
        train_data["user_emb_id"].values,
        train_data["movie_emb_id"].values,
        train_data["rating"].values,
    )

    baseline_val_dataset = BaselineDataset(
        val_data["user_emb_id"].values,
        val_data["movie_emb_id"].values,
        val_data["rating"].values,
    )

    baseline_train_loader = DataLoader(
        baseline_train_dataset,
        batch_size=config["BATCH_SIZE"],
        shuffle=True,
        num_workers=0,
    )
    baseline_val_loader = DataLoader(
        baseline_val_dataset,
        batch_size=config["BATCH_SIZE"],
        shuffle=False,
        num_workers=0,
    )

    # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    criterion = nn.MSELoss()
    optimizer = optim.Adam(
        model.parameters(), lr=config["LEARNING_RATE"], weight_decay=1e-6
    )
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="min", factor=0.6, patience=5, min_lr=1e-6
    )

    # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨ä¸“é—¨çš„baselineè®­ç»ƒå‡½æ•°ï¼‰
    best_model_state, training_history = train_baseline_model_with_metrics(
        model,
        baseline_train_loader,
        baseline_val_loader,
        criterion,
        optimizer,
        scheduler,
        device,
        config["NUM_EPOCHS"],
        patience=10,
    )

    # è¯„ä¼°æ¨¡å‹ï¼ˆä½¿ç”¨ä¸“é—¨çš„baselineè¯„ä¼°å‡½æ•°ï¼‰
    logging.info(f"å¼€å§‹è¯„ä¼°Baselineæ¨¡å‹: {model_name}")
    test_metrics = evaluate_baseline_model_detailed(model, test_data, device)

    # æ•´ç†ç»“æœ - ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜
    results = {
        "model_name": model_name,
        "model_type": "CFModel_Baseline",
        "training_history": training_history,
        "test_metrics": test_metrics,
        "model_params": {
            "total_params": total_params,
            "trainable_params": trainable_params,
            "k_factors": 100,
            "reg_strength": 0.0001,
        },
        "training_config": prepare_config_for_json(config),  # ä¿®å¤ï¼šè½¬æ¢deviceä¸ºå­—ç¬¦ä¸²
    }

    # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
    checkpoint = {
        "max_userid": max_userid,
        "max_movieid": max_movieid,
        "k_factors": 100,
        "reg_strength": 0.0001,
        "best_model_state": model.state_dict(),
        "model_type": "CFModel_Baseline",
        "training_history": training_history,
        "test_metrics": test_metrics,
        "has_scheduler": True,
    }

    model_path = data_path + f"model/model_checkpoint_baseline_with_scheduler.pt"
    torch.save(checkpoint, model_path, _use_new_zipfile_serialization=False)
    logging.info(f"Baselineæ¨¡å‹ä¿å­˜è‡³: {model_path}")

    # ä¿å­˜ç»“æœJSON - ç°åœ¨åº”è¯¥ä¸ä¼šå‡ºç°åºåˆ—åŒ–é”™è¯¯
    results_path = data_path + f"results/results_baseline_with_scheduler.json"
    Path(results_path).parent.mkdir(exist_ok=True)
    with open(results_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    logging.info(f"Baselineæ¨¡å‹ {model_name} è®­ç»ƒå’Œè¯„ä¼°å®Œæˆ!")
    logging.info(f"æµ‹è¯• RMSE: {test_metrics['RMSE']:.4f}")
    logging.info(f"æµ‹è¯• MAE: {test_metrics['MAE']:.4f}")

    return results


class BaselineDataset(torch.utils.data.Dataset):
    """Baselineæ¨¡å‹ä¸“ç”¨æ•°æ®é›†ï¼ˆä¸åŒ…å«æ—¶é—´ç‰¹å¾ï¼‰"""

    def __init__(self, user_ids, movie_ids, ratings):
        self.user_ids = user_ids
        self.movie_ids = movie_ids
        self.ratings = ratings

    def __len__(self):
        return len(self.user_ids)

    def __getitem__(self, idx):
        return (
            torch.LongTensor([self.user_ids[idx]]),
            torch.LongTensor([self.movie_ids[idx]]),
            torch.FloatTensor([self.ratings[idx]]),
        )


def train_baseline_model_with_metrics(
    model,
    train_loader,
    val_loader,
    criterion,
    optimizer,
    scheduler,
    device,
    num_epochs=30,
    patience=10,
):
    """ä¸“é—¨ä¸ºBaselineæ¨¡å‹çš„è®­ç»ƒå‡½æ•°"""
    best_val_loss = float("inf")
    patience_counter = 0
    best_model_state = None

    # è®°å½•è®­ç»ƒæŒ‡æ ‡
    training_history = {
        "train_losses": [],
        "val_losses": [],
        "train_rmse": [],
        "val_rmse": [],
        "learning_rates": [],
        "epoch_times": [],
        "best_epoch": 0,
        "total_epochs": 0,
    }

    logging.info(f"å¼€å§‹è®­ç»ƒBaselineæ¨¡å‹")
    start_time = time.time()

    for epoch in range(num_epochs):
        epoch_start = time.time()

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        num_batches = 0

        for user, movie, rating in train_loader:
            user = user.squeeze().to(device)
            movie = movie.squeeze().to(device)
            rating = rating.squeeze().to(device)

            optimizer.zero_grad()
            prediction = model(user, movie)  # Baselineæ¨¡å‹åªéœ€è¦userå’Œmovie

            # è®¡ç®—æŸå¤±ï¼ˆMSE + L2æ­£åˆ™åŒ–ï¼‰
            mse_loss = criterion(prediction, rating)

            # å¦‚æœæ¨¡å‹æœ‰æ­£åˆ™åŒ–æ–¹æ³•ï¼Œæ·»åŠ æ­£åˆ™åŒ–æŸå¤±
            if hasattr(model, "get_regularization_loss"):
                reg_loss = model.get_regularization_loss()
                total_loss = mse_loss + reg_loss
            else:
                total_loss = mse_loss

            total_loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

            optimizer.step()
            train_loss += mse_loss.item()  # åªè®°å½•MSEç”¨äºæ¯”è¾ƒ
            num_batches += 1

        avg_train_loss = train_loss / num_batches
        train_rmse = math.sqrt(avg_train_loss)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        num_val_batches = 0

        with torch.no_grad():
            for user, movie, rating in val_loader:
                user = user.squeeze().to(device)
                movie = movie.squeeze().to(device)
                rating = rating.squeeze().to(device)

                prediction = model(user, movie)  # Baselineæ¨¡å‹åªéœ€è¦userå’Œmovie
                loss = criterion(prediction, rating)
                val_loss += loss.item()
                num_val_batches += 1

        avg_val_loss = val_loss / num_val_batches
        val_rmse = math.sqrt(avg_val_loss)

        # è®°å½•å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]["lr"]

        # å­¦ä¹ ç‡è°ƒåº¦
        if scheduler:
            scheduler.step(avg_val_loss)

        # è®°å½•æŒ‡æ ‡
        training_history["train_losses"].append(avg_train_loss)
        training_history["val_losses"].append(avg_val_loss)
        training_history["train_rmse"].append(train_rmse)
        training_history["val_rmse"].append(val_rmse)
        training_history["learning_rates"].append(current_lr)

        epoch_time = time.time() - epoch_start
        training_history["epoch_times"].append(epoch_time)

        # æ‰“å°è®­ç»ƒä¿¡æ¯
        logging.info(f"Epoch {epoch+1}/{num_epochs} ({epoch_time:.2f}s)")
        logging.info(f"Train Loss: {avg_train_loss:.4f}, Train RMSE: {train_rmse:.4f}")
        logging.info(f"Val Loss: {avg_val_loss:.4f}, Val RMSE: {val_rmse:.4f}")
        logging.info(f"Learning rate: {current_lr:.6f}")

        # æ—©åœæ£€æŸ¥
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict().copy()
            patience_counter = 0
            training_history["best_epoch"] = epoch
            logging.info(f"New best validation loss: {avg_val_loss:.4f}")
        else:
            patience_counter += 1

        if patience_counter >= patience:
            logging.info(f"Early stopping at epoch {epoch+1}")
            if best_model_state is not None:
                model.load_state_dict(best_model_state)
            break

    training_history["total_epochs"] = epoch + 1
    total_time = time.time() - start_time
    training_history["total_training_time"] = total_time

    # æœ€ç»ˆç»Ÿè®¡
    best_rmse = math.sqrt(best_val_loss)
    logging.info(f"Baselineè®­ç»ƒå®Œæˆï¼æ€»æ—¶é—´: {total_time:.2f}s")
    logging.info(f"Best validation loss: {best_val_loss:.4f}")
    logging.info(f"Best validation RMSE: {best_rmse:.4f}")

    return best_model_state, training_history


def evaluate_baseline_model_detailed(model, test_data, device):
    """ä¸“é—¨ä¸ºBaselineæ¨¡å‹çš„è¯¦ç»†è¯„ä¼°å‡½æ•°"""
    model.eval()
    predictions = []
    actuals = []

    start_time = time.time()

    with torch.no_grad():
        for _, row in test_data.iterrows():
            user_id = torch.LongTensor([row["user_emb_id"]]).to(device)
            movie_id = torch.LongTensor([row["movie_emb_id"]]).to(device)

            pred = model(user_id, movie_id)  # Baselineæ¨¡å‹åªéœ€è¦userå’Œmovie
            predictions.append(pred.cpu().item())
            actuals.append(row["rating"])

    inference_time = time.time() - start_time

    # è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡ï¼ˆä¸å…¶ä»–æ¨¡å‹ç›¸åŒï¼‰
    predictions = np.array(predictions)
    actuals = np.array(actuals)

    # åŸºæœ¬æŒ‡æ ‡
    mse = np.mean((predictions - actuals) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(predictions - actuals))

    # å…¶ä»–æŒ‡æ ‡
    mape = (
        np.mean(np.abs((actuals - predictions) / actuals)) * 100
    )  # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®

    # è¯„åˆ†åˆ†å¸ƒç»Ÿè®¡
    pred_mean = np.mean(predictions)
    pred_std = np.std(predictions)
    actual_mean = np.mean(actuals)
    actual_std = np.std(actuals)

    # ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(predictions, actuals)[0, 1]

    # æŒ‰è¯„åˆ†åŒºé—´çš„å‡†ç¡®åº¦
    rating_accuracy = {}
    for rating in [1, 2, 3, 4, 5]:
        mask = actuals == rating
        if np.sum(mask) > 0:
            rating_predictions = predictions[mask]
            rating_mae = np.mean(np.abs(rating_predictions - rating))
            rating_accuracy[f"rating_{rating}_mae"] = rating_mae

    return {
        "MSE": mse,
        "RMSE": rmse,
        "MAE": mae,
        "MAPE": mape,
        "Correlation": correlation,
        "Inference_Time": inference_time,
        "Predictions_Mean": pred_mean,
        "Predictions_Std": pred_std,
        "Actuals_Mean": actual_mean,
        "Actuals_Std": actual_std,
        "predictions": predictions.tolist(),
        "actuals": actuals.tolist(),
        **rating_accuracy,
    }


def main():
    """ä¸»å‡½æ•°ï¼šè®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹ï¼ˆåŒ…æ‹¬baselineï¼‰"""
    # è®¾ç½®æ—¥å¿— - æ¯æ¬¡è¿è¡Œæ—¶æ¸…ç©ºæ—¥å¿—æ–‡ä»¶
    log_file = data_path + "training_comparison_log.txt"
    
    # åˆ é™¤æ—§æ—¥å¿—æ–‡ä»¶
    log_path = Path(log_file)
    if log_path.exists():
        log_path.unlink()
        print(f"ğŸ—‘ï¸  å·²æ¸…ç©ºæ—§æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8", mode='w'),  # ä½¿ç”¨ 'w' æ¨¡å¼
            logging.StreamHandler(),
        ],
        force=True  # å¼ºåˆ¶é‡æ–°é…ç½®logging
    )

    # è®°å½•å¼€å§‹ä¿¡æ¯
    logging.info("=" * 80)
    logging.info("ğŸ†• æ–°çš„æ¨¡å‹è®­ç»ƒæ¯”è¾ƒæµç¨‹å¼€å§‹")
    logging.info("=" * 80)

    # é…ç½®å‚æ•° - ä¸train.pyä¿æŒå®Œå…¨ä¸€è‡´
    config = {
        "DEVICE": torch.device("cuda" if torch.cuda.is_available() else "cpu"),
        "K_FACTORS": 100, 
        "TIME_FACTORS": 40,
        "BATCH_SIZE": 256,
        'NUM_EPOCHS': 30,
        'LEARNING_RATE': 0.001,
        "REG_STRENGTH": 0.001,
        "NUM_EXPERTS": 4,
        
        'NUM_EPOCHS_PER_STAGE': [30, 30, 30], 
        'LEARNING_RATES': [0.001, 0.001, 0.0005], 
    }

    logging.info(f'ä½¿ç”¨è®¾å¤‡: {config["DEVICE"]}')
    logging.info(f"é…ç½®å‚æ•°: {config}")
    logging.info(f"å­¦ä¹ ç‡è°ƒåº¦å™¨: ReduceLROnPlateau (factor=0.6, patience=5)")

    # å‡†å¤‡æ•°æ®
    split_path = data_path + "split_data"

    if check_split_data_exists(split_path):
        logging.info("åŠ è½½ç°æœ‰æ•°æ®åˆ†å‰²...")
        train_data, val_data, test_data = load_existing_split_data(split_path)
    else:
        logging.info("åˆ›å»ºæ–°çš„æ•°æ®åˆ†å‰²...")
        ratings, users, movies = load_data(
            data_path + "ratings.csv", data_path + "users.csv", data_path + "movies.csv"
        )
        train_data, val_data, test_data = create_time_aware_split(
            ratings, random_state=42
        )
        save_split_data(train_data, val_data, test_data, split_path)

    logging.info(
        f"æ•°æ®åˆ†å‰² - è®­ç»ƒ: {len(train_data)}, éªŒè¯: {len(val_data)}, æµ‹è¯•: {len(test_data)}"
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºéMMOEå’ŒéBaselineæ¨¡å‹ï¼‰
    train_dataset = MovieLensDataset(
        train_data["user_emb_id"].values,
        train_data["movie_emb_id"].values,
        train_data["rating"].values,
        train_data["daytime"].values,
        train_data["is_weekend"].values,
        train_data["year"].values,
    )

    val_dataset = MovieLensDataset(
        val_data["user_emb_id"].values,
        val_data["movie_emb_id"].values,
        val_data["rating"].values,
        val_data["daytime"].values,
        val_data["is_weekend"].values,
        val_data["year"].values,
    )

    train_loader = DataLoader(
        train_dataset, batch_size=config["BATCH_SIZE"], shuffle=True, num_workers=0
    )
    val_loader = DataLoader(
        val_dataset, batch_size=config["BATCH_SIZE"], shuffle=False, num_workers=0
    )

    # è·å–æœ€å¤§ID
    max_userid = train_data["user_emb_id"].max()
    max_movieid = train_data["movie_emb_id"].max()

    # å®šä¹‰è¦è®­ç»ƒçš„æ—¶é—´æ„ŸçŸ¥æ¨¡å‹
    models_to_train = [
        (UserTimeModel, "ç”¨æˆ·æ—¶é—´æ„ŸçŸ¥æ¨¡å‹"),
        (IndependentTimeModel, "ç‹¬ç«‹æ—¶é—´ç‰¹å¾æ¨¡å‹"),
        (UMTimeModel, "ç”¨æˆ·ç”µå½±æ—¶é—´æ„ŸçŸ¥æ¨¡å‹"),
    ]

    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_results = {}

    # è®­ç»ƒbaselineæ¨¡å‹
    try:
        baseline_results = train_and_evaluate_baseline_model(
            "Baseline Collaborative Filtering",
            max_userid,
            max_movieid,
            train_data,
            val_data,
            test_data,
            config["DEVICE"],
            config,
        )
        all_results[baseline_results["model_type"]] = baseline_results
    except Exception as e:
        logging.error(f"è®­ç»ƒBaselineæ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        import traceback

        logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    # è®­ç»ƒæ—¶é—´æ„ŸçŸ¥æ¨¡å‹
    for model_class, model_name in models_to_train:
        try:
            results = train_and_evaluate_model(
                model_class,
                model_name,
                max_userid,
                max_movieid,
                train_loader,
                val_loader,
                test_data,
                config["DEVICE"],
                config,
            )
            all_results[results["model_type"]] = results
        except Exception as e:
            logging.error(f"è®­ç»ƒæ¨¡å‹ {model_name} æ—¶å‡ºé”™: {str(e)}")
            import traceback

            logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            continue

    # è®­ç»ƒMMOEæ¨¡å‹
    try:
        mmoe_results = train_and_evaluate_mmoe_model(
            "ä¸¤é˜¶æ®µMMoEæ¨¡å‹(å¸¦å­¦ä¹ ç‡è°ƒåº¦)",
            max_userid,
            max_movieid,
            train_data,
            val_data,
            test_data,
            config["DEVICE"],
            config,
        )
        all_results[mmoe_results["model_type"]] = mmoe_results
    except Exception as e:
        logging.error(f"è®­ç»ƒMMOEæ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        import traceback

        logging.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    # ä¿å­˜æ‰€æœ‰ç»“æœçš„æ±‡æ€»ï¼ˆåŒ…æ‹¬baselineï¼‰
    summary_path = data_path + "results/all_models_summary_with_baseline.json"
    Path(summary_path).parent.mkdir(exist_ok=True)
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)

    logging.info(f"\n{'='*60}")
    logging.info("æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    logging.info("ç»“æœæ±‡æ€»:")

    for model_type, results in all_results.items():
        test_metrics = results["test_metrics"]
        training_history = results["training_history"]

        # æ˜¾ç¤ºå­¦ä¹ ç‡å˜åŒ–ä¿¡æ¯
        lr_info = ""
        if "learning_rates" in training_history and training_history["learning_rates"]:
            initial_lr = training_history["learning_rates"][0]
            final_lr = training_history["learning_rates"][-1]
            lr_reduction = (initial_lr - final_lr) / initial_lr * 100
            lr_info = f", å­¦ä¹ ç‡: {initial_lr:.6f}â†’{final_lr:.6f}(-{lr_reduction:.1f}%)"

        logging.info(f"{results['model_name']}:")
        logging.info(f"  RMSE: {test_metrics['RMSE']:.4f}")
        logging.info(f"  MAE: {test_metrics['MAE']:.4f}")
        logging.info(f"  è®­ç»ƒæ—¶é—´: {training_history['total_training_time']:.2f}s")
        logging.info(
            f"  å‚æ•°æ•°é‡: {results['model_params']['total_params']:,}{lr_info}"
        )

    return all_results


if __name__ == "__main__":
    main()
