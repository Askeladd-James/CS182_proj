"""
å®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œæ¯”è¾ƒæµç¨‹ï¼ˆåŒ…æ‹¬baselineï¼‰
"""
import subprocess
import sys
import logging
import time
from pathlib import Path
from data_process import data_path

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    log_file = Path(data_path) / 'full_comparison_log.txt'
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def run_baseline_training():
    """è¿è¡Œbaselineæ¨¡å‹è®­ç»ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è®­ç»ƒBaselineæ¨¡å‹...")
    
    try:
        # æ·»åŠ originç›®å½•åˆ°è·¯å¾„
        origin_path = Path(__file__).parent.parent / 'origin'
        if str(origin_path) not in sys.path:
            sys.path.insert(0, str(origin_path))
        
        # å¯¼å…¥å¹¶è¿è¡Œbaselineè®­ç»ƒ
        import train as baseline_train
        
        # è¿è¡Œbaselineè®­ç»ƒ
        model, test_data, results = baseline_train.main()
        logger.info("âœ… Baselineæ¨¡å‹è®­ç»ƒå®Œæˆ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Baselineè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        logger.error(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}")
        return False
    finally:
        # æ¸…ç†è·¯å¾„
        if str(origin_path) in sys.path:
            sys.path.remove(str(origin_path))

def run_time_aware_training():
    """è¿è¡Œæ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒ"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è®­ç»ƒæ—¶é—´æ„ŸçŸ¥æ¨¡å‹...")
    
    try:
        # è¿è¡Œæ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒ
        import train_comparison
        results = train_comparison.main()
        logger.info("âœ… æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        return True
    except Exception as e:
        logger.error(f"âŒ æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return False

def run_analysis():
    """è¿è¡Œæ¨¡å‹åˆ†æ"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹æ¨¡å‹åˆ†æé˜¶æ®µ...")
    
    try:
        # è¿è¡Œåˆ†æè„šæœ¬
        import model_comparison
        analyzer, summary = model_comparison.main()
        logger.info("âœ… æ¨¡å‹åˆ†æå®Œæˆ!")
        return analyzer, summary
    except Exception as e:
        logger.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return None, None

def check_data_availability():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    logger = logging.getLogger(__name__)
    
    required_files = [
        'ratings.csv',
        'users.csv', 
        'movies.csv'
    ]
    
    missing_files = []
    for file_name in required_files:
        file_path = Path(data_path) / file_name
        if not file_path.exists():
            missing_files.append(file_name)
    
    if missing_files:
        logger.error(f"ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶: {missing_files}")
        logger.error(f"è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äº {data_path} ç›®å½•ä¸­:")
        for file_name in missing_files:
            logger.error(f"  - {file_name}")
        return False
    
    logger.info("âœ… æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶éƒ½å­˜åœ¨")
    return True

def print_progress_summary(baseline_success, time_aware_success, analysis_success):
    """æ‰“å°è¿›åº¦æ€»ç»“"""
    logger = logging.getLogger(__name__)
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š æ‰§è¡Œè¿›åº¦æ€»ç»“")
    logger.info("=" * 80)
    
    steps = [
        ("Baselineæ¨¡å‹è®­ç»ƒ", baseline_success),
        ("æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒ", time_aware_success), 
        ("æ¨¡å‹åˆ†æå’Œæ¯”è¾ƒ", analysis_success)
    ]
    
    success_count = sum(1 for _, success in steps if success)
    total_steps = len(steps)
    
    for step_name, success in steps:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        logger.info(f"{step_name}: {status}")
    
    logger.info(f"\næ€»ä½“è¿›åº¦: {success_count}/{total_steps} æ­¥éª¤å®Œæˆ")
    
    if success_count == total_steps:
        logger.info("ğŸ‰ æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸå®Œæˆï¼")
    elif success_count > 0:
        logger.info("âš ï¸  éƒ¨åˆ†æ­¥éª¤å®Œæˆï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æ­¥éª¤")
    else:
        logger.info("âŒ æ‰€æœ‰æ­¥éª¤éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®")
    
    return success_count == total_steps

def main():
    """ä¸»æµç¨‹ - åŒ…å«baselineå’Œæ—¶é—´æ„ŸçŸ¥æ¨¡å‹çš„å®Œæ•´è®­ç»ƒæµç¨‹"""
    start_time = time.time()
    logger = setup_logging()
    
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„æ¨¡å‹æ¯”è¾ƒæµç¨‹ï¼ˆåŒ…æ‹¬Baselineï¼‰...")
    logger.info(f"ğŸ“ å·¥ä½œç›®å½•: {data_path}")
    
    # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
    if not check_data_availability():
        logger.error("âŒ æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
        return None, None
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    directories = ['model', 'results', 'analysis_plots']
    for dir_name in directories:
        dir_path = Path(data_path) / dir_name
        dir_path.mkdir(exist_ok=True)
        logger.info(f"ğŸ“‚ ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
    
    # åˆå§‹åŒ–ç»“æœè¿½è¸ª
    baseline_success = False
    time_aware_success = False
    analysis_success = False
    
    # é˜¶æ®µ1ï¼šè®­ç»ƒBaselineæ¨¡å‹
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”„ é˜¶æ®µ1ï¼šè®­ç»ƒBaselineæ¨¡å‹")
    logger.info("=" * 80)
    
    baseline_start = time.time()
    baseline_success = run_baseline_training()
    baseline_time = time.time() - baseline_start
    
    if baseline_success:
        logger.info(f"âœ… Baselineè®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {baseline_time:.2f}ç§’")
    else:
        logger.warning("âš ï¸  Baselineè®­ç»ƒå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–æ¨¡å‹")
    
    # é˜¶æ®µ2ï¼šè®­ç»ƒæ—¶é—´æ„ŸçŸ¥æ¨¡å‹ï¼ˆåŒ…æ‹¬MMOEï¼‰
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”„ é˜¶æ®µ2ï¼šè®­ç»ƒæ—¶é—´æ„ŸçŸ¥æ¨¡å‹ï¼ˆåŒ…æ‹¬MMOEï¼‰")
    logger.info("=" * 80)
    
    time_aware_start = time.time()
    time_aware_success = run_time_aware_training()
    time_aware_time = time.time() - time_aware_start
    
    if time_aware_success:
        logger.info(f"âœ… æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {time_aware_time:.2f}ç§’")
    else:
        logger.error("âŒ æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒå¤±è´¥")
    
    # é˜¶æ®µ3ï¼šæ¨¡å‹åˆ†æå’Œæ¯”è¾ƒï¼ˆåªæœ‰åœ¨è‡³å°‘æœ‰ä¸€ä¸ªæ¨¡å‹è®­ç»ƒæˆåŠŸæ—¶æ‰æ‰§è¡Œï¼‰
    if baseline_success or time_aware_success:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ”„ é˜¶æ®µ3ï¼šæ¨¡å‹åˆ†æå’Œæ¯”è¾ƒ")
        logger.info("=" * 80)
        
        analysis_start = time.time()
        analyzer, summary = run_analysis()
        analysis_time = time.time() - analysis_start
        
        if analyzer is not None:
            analysis_success = True
            logger.info(f"âœ… æ¨¡å‹åˆ†æå®Œæˆï¼Œè€—æ—¶: {analysis_time:.2f}ç§’")
        else:
            logger.error("âŒ æ¨¡å‹åˆ†æå¤±è´¥")
    else:
        logger.error("âŒ æ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹ï¼Œè·³è¿‡åˆ†æé˜¶æ®µ")
        analyzer, summary = None, None
    
    # æ€»ç»“
    total_time = time.time() - start_time
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 80)
    
    # æ‰“å°è¯¦ç»†çš„æ€»ç»“
    all_success = print_progress_summary(baseline_success, time_aware_success, analysis_success)
    
    logger.info(f"\nâ±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")
    
    if baseline_success:
        logger.info(f"   - Baselineè®­ç»ƒ: {baseline_time:.2f}ç§’")
    if time_aware_success:
        logger.info(f"   - æ—¶é—´æ„ŸçŸ¥æ¨¡å‹è®­ç»ƒ: {time_aware_time:.2f}ç§’")
    if analysis_success:
        logger.info(f"   - æ¨¡å‹åˆ†æ: {analysis_time:.2f}ç§’")
    
    # è¾“å‡ºæ–‡ä»¶ä½ç½®ä¿¡æ¯
    if all_success:
        logger.info(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        logger.info(f"ğŸ“Š ç»“æœæ–‡ä»¶: {data_path}results/")
        logger.info(f"ğŸ¤– æ¨¡å‹æ–‡ä»¶: {data_path}model/")
        logger.info(f"ğŸ“ˆ åˆ†æå›¾è¡¨: {data_path}analysis_plots/")
        logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {data_path}full_comparison_log.txt")
        
        # å¦‚æœæœ‰å…·ä½“çš„æ±‡æ€»æ–‡ä»¶ï¼Œä¹Ÿè®°å½•ä¸€ä¸‹
        summary_files = [
            'all_models_summary_with_baseline.json',
            'all_models_summary_with_scheduler.json'
        ]
        
        for summary_file in summary_files:
            summary_path = Path(data_path) / 'results' / summary_file
            if summary_path.exists():
                logger.info(f"ğŸ“„ æ¨¡å‹æ±‡æ€»: {summary_path}")
                break
    
    return analyzer, summary

if __name__ == "__main__":
    analyzer, summary = main()