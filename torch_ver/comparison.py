"""
å®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å’Œæ¯”è¾ƒæµç¨‹ï¼ˆåŒ…æ‹¬baselineï¼‰
"""
import logging
import time
from pathlib import Path
from data_process import data_path

def setup_logging():
    """è®¾ç½®æ—¥å¿— - æ¯æ¬¡è¿è¡Œæ—¶æ¸…ç©ºæ—¥å¿—æ–‡ä»¶"""
    log_file = Path(data_path) / 'full_comparison_log.txt'
    
    # æ¯æ¬¡è¿è¡Œæ—¶åˆ é™¤æ—§çš„æ—¥å¿—æ–‡ä»¶
    if log_file.exists():
        log_file.unlink()
        print(f"ğŸ—‘ï¸  å·²æ¸…ç©ºæ—§æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8', mode='w'),  # ä½¿ç”¨ 'w' æ¨¡å¼ç¡®ä¿è¦†ç›–
            logging.StreamHandler()
        ],
        force=True  # å¼ºåˆ¶é‡æ–°é…ç½®logging
    )
    
    # è®°å½•æ—¥å¿—å¼€å§‹
    logger = logging.getLogger(__name__)
    logger.info("=" * 80)
    logger.info("ğŸ†• æ–°çš„å®Œæ•´æ¨¡å‹æ¯”è¾ƒæµç¨‹å¼€å§‹")
    logger.info("=" * 80)
    
    return logger

def run_all_model_training():
    """è¿è¡Œæ‰€æœ‰æ¨¡å‹è®­ç»ƒï¼ˆåŒ…æ‹¬baselineå’Œæ—¶é—´æ„ŸçŸ¥æ¨¡å‹ï¼‰"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
    
    try:
        # è¿è¡Œæ‰€æœ‰æ¨¡å‹è®­ç»ƒï¼ˆåŒ…æ‹¬baselineã€æ—¶é—´æ„ŸçŸ¥æ¨¡å‹ã€MMOEï¼‰
        import train_comparison
        results = train_comparison.main()
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        return True, results
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return False, None

def run_analysis():
    """è¿è¡Œæ¨¡å‹åˆ†æ"""
    logger = logging.getLogger(__name__)
    logger.info("å¼€å§‹æ¨¡å‹åˆ†æé˜¶æ®µ...")
    
    try:
        # è¿è¡Œåˆ†æè„šæœ¬
        import model_comparison
        analyzer, summary = model_comparison.main()
        logger.info("âœ… æ¨¡å‹åˆ†æå®Œæˆ!")
        return analyzer, summary
    except Exception as e:
        logger.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None, None

def check_data_availability():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    logger = logging.getLogger(__name__)
    
    required_files = [
        'ratings.csv',
        'users.csv', 
        'movies.csv'
    ]
    
    missing_files = []
    for file_name in required_files:
        file_path = Path(data_path) / file_name
        if not file_path.exists():
            missing_files.append(file_name)
    
    if missing_files:
        logger.error(f"ç¼ºå°‘å¿…è¦çš„æ•°æ®æ–‡ä»¶: {missing_files}")
        logger.error(f"è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äº {data_path} ç›®å½•ä¸­:")
        for file_name in missing_files:
            logger.error(f"  - {file_name}")
        return False
    
    logger.info("âœ… æ‰€æœ‰å¿…è¦çš„æ•°æ®æ–‡ä»¶éƒ½å­˜åœ¨")
    return True

def print_progress_summary(training_success, analysis_success):
    """æ‰“å°è¿›åº¦æ€»ç»“"""
    logger = logging.getLogger(__name__)
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š æ‰§è¡Œè¿›åº¦æ€»ç»“")
    logger.info("=" * 80)
    
    steps = [
        ("æ‰€æœ‰æ¨¡å‹è®­ç»ƒ", training_success),
        ("æ¨¡å‹åˆ†æå’Œæ¯”è¾ƒ", analysis_success)
    ]
    
    success_count = sum(1 for _, success in steps if success)
    total_steps = len(steps)
    
    for step_name, success in steps:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        logger.info(f"{step_name}: {status}")
    
    logger.info(f"\næ€»ä½“è¿›åº¦: {success_count}/{total_steps} æ­¥éª¤å®Œæˆ")
    
    if success_count == total_steps:
        logger.info("ğŸ‰ æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸå®Œæˆï¼")
    elif success_count > 0:
        logger.info("âš ï¸  éƒ¨åˆ†æ­¥éª¤å®Œæˆï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æ­¥éª¤")
    else:
        logger.info("âŒ æ‰€æœ‰æ­¥éª¤éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®")
    
    return success_count == total_steps

def main():
    """ä¸»æµç¨‹ - è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¿›è¡Œåˆ†æ"""
    start_time = time.time()
    logger = setup_logging()
    
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„æ¨¡å‹æ¯”è¾ƒæµç¨‹...")
    logger.info(f"ğŸ“ å·¥ä½œç›®å½•: {data_path}")
    
    # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
    if not check_data_availability():
        logger.error("âŒ æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢æµç¨‹")
        return None, None
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    directories = ['model', 'results', 'analysis_plots']
    for dir_name in directories:
        dir_path = Path(data_path) / dir_name
        dir_path.mkdir(exist_ok=True)
        logger.info(f"ğŸ“‚ ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
    
    # é˜¶æ®µ1ï¼šè®­ç»ƒæ‰€æœ‰æ¨¡å‹ï¼ˆBaseline + æ—¶é—´æ„ŸçŸ¥æ¨¡å‹ + MMOEï¼‰
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ”„ é˜¶æ®µ1ï¼šè®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    logger.info("=" * 80)
    logger.info("åŒ…æ‹¬ï¼šBaselineã€æ—¶é—´æ„ŸçŸ¥æ¨¡å‹ï¼ˆUserTimeã€IndependentTimeã€UMTimeï¼‰ã€MMOE")
    
    training_start = time.time()
    training_success, training_results = run_all_model_training()
    training_time = time.time() - training_start
    
    if training_success:
        logger.info(f"âœ… æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœæ¦‚è§ˆ
        if training_results:
            logger.info("\nğŸ“Š è®­ç»ƒç»“æœæ¦‚è§ˆ:")
            for model_type, results in training_results.items():
                test_metrics = results.get('test_metrics', {})
                rmse = test_metrics.get('RMSE', 'N/A')
                mae = test_metrics.get('MAE', 'N/A')
                logger.info(f"  {results.get('model_name', model_type)}:")
                logger.info(f"    RMSE: {rmse}")
                logger.info(f"    MAE: {mae}")
    else:
        logger.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
    
    # é˜¶æ®µ2ï¼šæ¨¡å‹åˆ†æå’Œæ¯”è¾ƒï¼ˆåªæœ‰åœ¨è®­ç»ƒæˆåŠŸæ—¶æ‰æ‰§è¡Œï¼‰
    analysis_success = False
    if training_success:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ”„ é˜¶æ®µ2ï¼šæ¨¡å‹åˆ†æå’Œæ¯”è¾ƒ")
        logger.info("=" * 80)
        
        analysis_start = time.time()
        analyzer, summary = run_analysis()
        analysis_time = time.time() - analysis_start
        
        if analyzer is not None:
            analysis_success = True
            logger.info(f"âœ… æ¨¡å‹åˆ†æå®Œæˆï¼Œè€—æ—¶: {analysis_time:.2f}ç§’")
        else:
            logger.error("âŒ æ¨¡å‹åˆ†æå¤±è´¥")
    else:
        logger.error("âŒ è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡åˆ†æé˜¶æ®µ")
        analyzer, summary = None, None
    
    # æ€»ç»“
    total_time = time.time() - start_time
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 80)
    
    # æ‰“å°è¯¦ç»†çš„æ€»ç»“
    all_success = print_progress_summary(training_success, analysis_success)
    
    logger.info(f"\nâ±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")
    
    if training_success:
        logger.info(f"   - æ¨¡å‹è®­ç»ƒ: {training_time:.2f}ç§’")
    if analysis_success:
        logger.info(f"   - æ¨¡å‹åˆ†æ: {analysis_time:.2f}ç§’")
    
    # è¾“å‡ºæ–‡ä»¶ä½ç½®ä¿¡æ¯
    if all_success:
        logger.info(f"\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        logger.info(f"ğŸ“Š ç»“æœæ–‡ä»¶: {data_path}results/")
        logger.info(f"ğŸ¤– æ¨¡å‹æ–‡ä»¶: {data_path}model/")
        logger.info(f"ğŸ“ˆ åˆ†æå›¾è¡¨: {data_path}analysis_plots/")
        logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {data_path}full_comparison_log.txt")
        
        # æ£€æŸ¥æ±‡æ€»æ–‡ä»¶
        summary_files = [
            'all_models_summary_with_baseline.json',
            'all_models_summary_with_scheduler.json'
        ]
        
        for summary_file in summary_files:
            summary_path = Path(data_path) / 'results' / summary_file
            if summary_path.exists():
                logger.info(f"ğŸ“„ æ¨¡å‹æ±‡æ€»: {summary_path}")
                break
    
    return analyzer, summary

if __name__ == "__main__":
    analyzer, summary = main()
    
    # å¦‚æœè¿è¡ŒæˆåŠŸï¼Œæä¾›ç®€å•çš„äº¤äº’æç¤º
    if analyzer is not None:
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå’Œåˆ†æå®Œæˆï¼")
        print("="*60)
        print("ä¸»è¦è¾“å‡ºæ–‡ä»¶:")
        print(f"â€¢ æ¨¡å‹æ€§èƒ½æ±‡æ€»: {data_path}results/all_models_summary_with_baseline.json")
        print(f"â€¢ æ€§èƒ½å¯¹æ¯”å›¾è¡¨: {data_path}analysis_plots/")
        print(f"â€¢ è®­ç»ƒæ—¥å¿—: {data_path}full_comparison_log.txt")
        print("="*60)
    else:
        print("\nâŒ æµç¨‹æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†ä¿¡æ¯")