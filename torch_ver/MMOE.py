import torch
import torch.nn as nn
import numpy as np

class TwoStageMMoEModel(nn.Module):
    """æ”¹è¿›çš„ä¸¤é˜¶æ®µMMoEæ¨¡å‹ - å‚è€ƒUMTimeModelçš„æˆåŠŸè®¾è®¡"""
    def __init__(self, n_users, m_items, k_factors=80, time_factors=20, reg_strength=0.01, num_experts=4):
        super(TwoStageMMoEModel, self).__init__()
        self.reg_strength = reg_strength
        self.name = "TwoStage_MMoE"
        self.k_factors = k_factors
        self.time_factors = time_factors
        self.num_experts = num_experts
        
        # ============= å…±äº«åµŒå…¥å±‚ =============
        self.user_embedding = nn.Embedding(n_users, k_factors)
        self.item_embedding = nn.Embedding(m_items, k_factors)
        
        # ğŸ”§ ä¿®å¤1: å®Œæ•´çš„æ—¶é—´ç‰¹å¾åµŒå…¥ - å‚è€ƒUMTimeModel
        self.daytime_embedding = nn.Embedding(3, time_factors)
        self.weekend_embedding = nn.Embedding(2, time_factors)
        self.year_embedding = nn.Embedding(20, time_factors)
        
        # åŸºç¡€åå·®é¡¹
        self.user_bias = nn.Embedding(n_users, 1)
        self.item_bias = nn.Embedding(m_items, 1)
        self.global_bias = nn.Parameter(torch.zeros(1))
        
        # ============= é˜¶æ®µ1ï¼šç®€åŒ–çš„æ—¶åºå»ºæ¨¡ç½‘ç»œ =============
        # ğŸ”§ ä¿®å¤2: ç®€åŒ–æ—¶åºç½‘ç»œï¼Œå‚è€ƒUMTimeModelçš„ç›´æ¥è®¾è®¡
        temporal_input_dim = k_factors + k_factors + time_factors * 3  # ç§»é™¤æ¨¡æ‹Ÿå†å²ç‰¹å¾
        
        self.temporal_feature_network = nn.Sequential(
            nn.Linear(temporal_input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1)
        )
        
        # ============= é˜¶æ®µ2ï¼šç®€åŒ–çš„ååŒè¿‡æ»¤ç½‘ç»œ - å‚è€ƒUMTimeModel =============
        # ğŸ”§ ä¿®å¤3: å®Œæ•´çš„æ—¶é—´åå·®é¡¹
        self.daytime_bias = nn.Embedding(3, 1)
        self.weekend_bias = nn.Embedding(2, 1)
        self.year_bias = nn.Embedding(20, 1)  # æ·»åŠ å¹´ä»½åå·®
        self.user_time_bias = nn.Embedding(n_users, 3)  # ç”¨æˆ·æ—¶é—´äº¤äº’åå·®
        
        # ğŸ”§ ä¿®å¤4: ç®€åŒ–CFç½‘ç»œ - ç§»é™¤å¤æ‚çš„æŠ•å½±å’Œç»´åº¦å˜æ¢
        # ç›´æ¥ä½¿ç”¨æ—¶é—´ç‰¹å¾èåˆï¼Œå‚è€ƒUMTimeModelçš„æˆåŠŸæ¨¡å¼
        self.cf_time_fusion = nn.Sequential(
            nn.Linear(k_factors + 3 * time_factors, time_factors * 2),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(time_factors * 2, 1)
        )
        
        # ============= é˜¶æ®µ3ï¼šMMoEèåˆå±‚ =============
        expert_input_dim = 2  # temporal_pred + cf_pred
        self.experts = nn.ModuleList([
            nn.Sequential(
                nn.Linear(expert_input_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(32, 16),
                nn.ReLU(),
                nn.Linear(16, 8)
            ) for _ in range(num_experts)
        ])
        
        gate_input_dim = k_factors + time_factors * 3
        self.gate_network = nn.Sequential(
            nn.Linear(gate_input_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, num_experts),
            nn.Softmax(dim=1)
        )
        
        self.final_layer = nn.Sequential(
            nn.Linear(8, 16),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(16, 1)
        )
        
        self.dropout = nn.Dropout(0.3)
        self._init_weights()
        
        self.training_stage = 1
    
    def _init_weights(self):
        """æ”¹è¿›çš„æƒé‡åˆå§‹åŒ– - å‚è€ƒUMTimeModel"""
        # ğŸ”§ ä¿®å¤5: ä½¿ç”¨æ›´ä¿å®ˆçš„åˆå§‹åŒ–ç­–ç•¥
        nn.init.normal_(self.user_embedding.weight, std=0.05)
        nn.init.normal_(self.item_embedding.weight, std=0.05)
        
        nn.init.normal_(self.user_bias.weight, std=0.01)
        nn.init.normal_(self.item_bias.weight, std=0.01)
        nn.init.constant_(self.global_bias, 0.0)
        
        nn.init.normal_(self.daytime_embedding.weight, std=0.01)
        nn.init.normal_(self.weekend_embedding.weight, std=0.01)
        nn.init.normal_(self.year_embedding.weight, std=0.01)
        
        nn.init.normal_(self.daytime_bias.weight, std=0.01)
        nn.init.normal_(self.weekend_bias.weight, std=0.01)
        nn.init.normal_(self.year_bias.weight, std=0.01)
        nn.init.normal_(self.user_time_bias.weight, std=0.01)
        
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0.01)
    
    def set_training_stage(self, stage):
        """è®¾ç½®è®­ç»ƒé˜¶æ®µ"""
        self.training_stage = stage
        
        if stage == 1:
            # æ—¶åºé˜¶æ®µï¼šåªè®­ç»ƒæ—¶åºç½‘ç»œ
            for param in self.parameters():
                param.requires_grad = False
            # ğŸ”§ ä¿®å¤6: åŒ…å«å…±äº«åµŒå…¥å±‚çš„è®­ç»ƒ
            for param in self.user_embedding.parameters():
                param.requires_grad = True
            for param in self.item_embedding.parameters():
                param.requires_grad = True
            for param in self.daytime_embedding.parameters():
                param.requires_grad = True
            for param in self.weekend_embedding.parameters():
                param.requires_grad = True
            for param in self.year_embedding.parameters():
                param.requires_grad = True
            for param in self.temporal_feature_network.parameters():
                param.requires_grad = True
                
        elif stage == 2:
            # CFé˜¶æ®µï¼šåªè®­ç»ƒCFç½‘ç»œå’Œåå·®é¡¹
            for param in self.parameters():
                param.requires_grad = False
            for param in self.user_bias.parameters():
                param.requires_grad = True
            for param in self.item_bias.parameters():
                param.requires_grad = True
            for param in self.daytime_bias.parameters():
                param.requires_grad = True
            for param in self.weekend_bias.parameters():
                param.requires_grad = True
            for param in self.year_bias.parameters():
                param.requires_grad = True
            for param in self.user_time_bias.parameters():
                param.requires_grad = True
            for param in self.cf_time_fusion.parameters():
                param.requires_grad = True
                
        elif stage == 3:
            # MMoEé˜¶æ®µï¼šåªè®­ç»ƒMMoEç½‘ç»œ
            for param in self.parameters():
                param.requires_grad = False
            for param in self.experts.parameters():
                param.requires_grad = True
            for param in self.gate_network.parameters():
                param.requires_grad = True
            for param in self.final_layer.parameters():
                param.requires_grad = True
                
        elif stage == 4:
            # è§£å†»æ‰€æœ‰å‚æ•°ç”¨äºè¯„ä¼°
            for param in self.parameters():
                param.requires_grad = True
    
    def forward_temporal_stage(self, user_input, item_input, daytime_input, weekend_input, year_input):
        """ğŸ”§ ä¿®å¤7: ç®€åŒ–æ—¶åºå»ºæ¨¡å‰å‘ä¼ æ’­ - ç§»é™¤æ¨¡æ‹Ÿå†å²ç‰¹å¾"""
        user_embedded = self.user_embedding(user_input)
        item_embedded = self.item_embedding(item_input)
        daytime_embedded = self.daytime_embedding(daytime_input)
        weekend_embedded = self.weekend_embedding(weekend_input)
        year_embedded = self.year_embedding(year_input)
        
        if self.training:
            user_embedded = self.dropout(user_embedded)
            item_embedded = self.dropout(item_embedded)
        
        # ğŸ”§ ç›´æ¥ç»„åˆç”¨æˆ·ã€ç‰©å“å’Œæ—¶é—´ç‰¹å¾
        combined_features = torch.cat([
            user_embedded,
            item_embedded,
            daytime_embedded, 
            weekend_embedded,
            year_embedded
        ], dim=1)
        
        # ç®€åŒ–çš„æ—¶åºé¢„æµ‹
        prediction = self.temporal_feature_network(combined_features)
        return prediction.squeeze()
    
    def forward_cf_stage(self, user_input, item_input, daytime_input, weekend_input, year_input):
        """ğŸ”§ ä¿®å¤8: ç®€åŒ–CFå‰å‘ä¼ æ’­ - å‚è€ƒUMTimeModelè®¾è®¡"""
        user_embedded = self.user_embedding(user_input)
        item_embedded = self.item_embedding(item_input)
        daytime_embedded = self.daytime_embedding(daytime_input)
        weekend_embedded = self.weekend_embedding(weekend_input)
        year_embedded = self.year_embedding(year_input)
        
        if self.training:
            user_embedded = self.dropout(user_embedded)
            item_embedded = self.dropout(item_embedded)
        
        # ğŸ”§ æ ¸å¿ƒäº¤äº’ - ç›´æ¥ç‚¹ç§¯ï¼Œå‚è€ƒUMTimeModel
        base_interaction = torch.sum(user_embedded * item_embedded, dim=1)
        
        # ğŸ”§ å®Œæ•´çš„åå·®é¡¹
        user_bias = self.user_bias(user_input).squeeze()
        item_bias = self.item_bias(item_input).squeeze()
        daytime_bias = self.daytime_bias(daytime_input).squeeze()
        weekend_bias = self.weekend_bias(weekend_input).squeeze()
        year_bias = self.year_bias(year_input).squeeze()
        
        # ğŸ”§ ç”¨æˆ·æ—¶é—´äº¤äº’åå·® - å‚è€ƒUMTimeModel
        time_bias = self.user_time_bias(user_input)
        user_daytime_bias = torch.gather(time_bias, 1, daytime_input.unsqueeze(1)).squeeze()
        
        # ğŸ”§ ç®€åŒ–çš„æ—¶é—´ç‰¹å¾èåˆ - å‚è€ƒUMTimeModel
        time_features = torch.cat([
            daytime_embedded, 
            weekend_embedded, 
            year_embedded
        ], dim=1)
        
        # å°†ç”¨æˆ·ç‰¹å¾ä¸æ—¶é—´ç‰¹å¾ç»“åˆ
        combined_features = torch.cat([user_embedded, time_features], dim=1)
        time_interaction = self.cf_time_fusion(combined_features).squeeze()
        
        # ğŸ”§ æœ€ç»ˆé¢„æµ‹ - å‚è€ƒUMTimeModelçš„æˆåŠŸæ¨¡å¼
        final_prediction = (base_interaction + user_bias + item_bias + 
                           daytime_bias + weekend_bias + year_bias + 
                           user_daytime_bias + time_interaction + self.global_bias)
        
        return final_prediction
    
    def forward_mmoe_stage(self, user_input, item_input, daytime_input, weekend_input, year_input, 
                          temporal_pred, cf_pred):
        """MMoEèåˆå‰å‘ä¼ æ’­"""
        # ç¡®ä¿é¢„æµ‹å€¼ç»´åº¦æ­£ç¡®
        if temporal_pred.dim() == 0:
            temporal_pred = temporal_pred.unsqueeze(0)
        if cf_pred.dim() == 0:
            cf_pred = cf_pred.unsqueeze(0)
            
        if temporal_pred.dim() > 1:
            temporal_pred = temporal_pred.squeeze()
        if cf_pred.dim() > 1:
            cf_pred = cf_pred.squeeze()
            
        batch_size = user_input.size(0)
        if temporal_pred.size(0) != batch_size:
            temporal_pred = temporal_pred.expand(batch_size)
        if cf_pred.size(0) != batch_size:
            cf_pred = cf_pred.expand(batch_size)
        
        # ç»„åˆä¸“å®¶è¾“å…¥
        expert_input = torch.stack([temporal_pred, cf_pred], dim=1)
        
        # é—¨æ§ç½‘ç»œè¾“å…¥
        user_embedded = self.user_embedding(user_input)
        daytime_embedded = self.daytime_embedding(daytime_input)
        weekend_embedded = self.weekend_embedding(weekend_input)
        year_embedded = self.year_embedding(year_input)
        
        gate_input = torch.cat([
            user_embedded, 
            daytime_embedded, 
            weekend_embedded, 
            year_embedded
        ], dim=1)
        
        # è®¡ç®—é—¨æ§æƒé‡
        gate_weights = self.gate_network(gate_input)
        
        # ä¸“å®¶ç½‘ç»œè¾“å‡º
        expert_outputs = []
        for expert in self.experts:
            expert_out = expert(expert_input)
            expert_outputs.append(expert_out)
        
        expert_outputs = torch.stack(expert_outputs, dim=2)
        
        # åŠ æƒèåˆ
        gate_weights = gate_weights.unsqueeze(1)
        weighted_output = torch.bmm(gate_weights, expert_outputs.transpose(1, 2))
        weighted_output = weighted_output.squeeze(1)
        
        # æœ€ç»ˆé¢„æµ‹
        final_prediction = self.final_layer(weighted_output)
        return final_prediction.squeeze()
    
    def forward(self, user_input, item_input, daytime_input, weekend_input, year_input, 
                temporal_pred=None, cf_pred=None, user_history_features=None):
        """å‰å‘ä¼ æ’­"""
        if self.training_stage == 1:
            return self.forward_temporal_stage(
                user_input, item_input, daytime_input, weekend_input, year_input
            )
        elif self.training_stage == 2:
            return self.forward_cf_stage(
                user_input, item_input, daytime_input, weekend_input, year_input
            )
        elif self.training_stage == 3:
            if temporal_pred is None or cf_pred is None:
                raise ValueError("MMoE stage requires both temporal_pred and cf_pred")
            return self.forward_mmoe_stage(
                user_input, item_input, daytime_input, weekend_input, year_input, temporal_pred, cf_pred
            )
        elif self.training_stage == 4:
            # è¯„ä¼°é˜¶æ®µï¼šä¾æ¬¡è°ƒç”¨ä¸‰ä¸ªé˜¶æ®µ
            self.training_stage = 1
            temporal_pred = self.forward_temporal_stage(
                user_input, item_input, daytime_input, weekend_input, year_input
            )
            
            self.training_stage = 2
            cf_pred = self.forward_cf_stage(
                user_input, item_input, daytime_input, weekend_input, year_input
            )
            
            self.training_stage = 3
            final_pred = self.forward_mmoe_stage(
                user_input, item_input, daytime_input, weekend_input, year_input, temporal_pred, cf_pred
            )
            
            self.training_stage = 4
            return final_pred
        else:
            raise ValueError(f"Unknown training stage: {self.training_stage}")
    
    def get_regularization_loss(self):
        """ğŸ”§ ä¿®å¤9: æ”¹è¿›çš„æ­£åˆ™åŒ–æŸå¤±"""
        reg_loss = 0
        
        # åŸºç¡€åµŒå…¥æ­£åˆ™åŒ–
        reg_loss += torch.norm(self.user_embedding.weight) * 0.1
        reg_loss += torch.norm(self.item_embedding.weight) * 0.1
        
        # æ—¶é—´ç‰¹å¾æ­£åˆ™åŒ–
        reg_loss += torch.norm(self.daytime_embedding.weight) * 0.05
        reg_loss += torch.norm(self.weekend_embedding.weight) * 0.05
        reg_loss += torch.norm(self.year_embedding.weight) * 0.05
        
        # æ ¹æ®è®­ç»ƒé˜¶æ®µè°ƒæ•´æ­£åˆ™åŒ–
        if self.training_stage == 1:
            reg_loss += sum(torch.norm(param) for param in self.temporal_feature_network.parameters()) * 0.01
        elif self.training_stage == 2:
            reg_loss += sum(torch.norm(param) for param in self.cf_time_fusion.parameters()) * 0.01
        elif self.training_stage == 3:
            reg_loss += sum(torch.norm(param) for expert in self.experts for param in expert.parameters()) * 0.005
            reg_loss += sum(torch.norm(param) for param in self.gate_network.parameters()) * 0.005
            reg_loss += sum(torch.norm(param) for param in self.final_layer.parameters()) * 0.005
        
        return self.reg_strength * reg_loss
    
    def rate(self, user_id, item_id, daytime=1, weekend=0, year=10):
        """é¢„æµ‹å•ä¸ªç”¨æˆ·å¯¹å•ä¸ªç‰©å“çš„è¯„åˆ†ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        self.eval()
        with torch.no_grad():
            user_tensor = torch.LongTensor([user_id])
            item_tensor = torch.LongTensor([item_id])
            daytime_tensor = torch.LongTensor([daytime])
            weekend_tensor = torch.LongTensor([weekend])
            year_tensor = torch.LongTensor([year])
            
            # è®¾ç½®ä¸ºè¯„ä¼°é˜¶æ®µ
            original_stage = self.training_stage
            self.training_stage = 4
            
            prediction = self.forward(user_tensor, item_tensor, daytime_tensor, 
                                    weekend_tensor, year_tensor)
            
            # æ¢å¤åŸå§‹é˜¶æ®µ
            self.training_stage = original_stage
            
            return prediction.item()